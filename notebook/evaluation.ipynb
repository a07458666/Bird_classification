{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "human-intelligence",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classified-institute",
   "metadata": {},
   "source": [
    "### import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "julian-financing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "from os import listdir\n",
    "from os import walk\n",
    "from torch import nn\n",
    "from tqdm import tqdm \n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torchvision import datasets, transforms\n",
    "from facenet_pytorch import InceptionResnetV1, fixed_image_standardization\n",
    "\n",
    "import PIL.Image as Image\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-batch",
   "metadata": {},
   "source": [
    "### check gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "catholic-stations",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version:1.9.0+cu102\n",
      "Available GPUs: GeForce RTX 2080 Ti GeForce GTX 1080 Ti "
     ]
    }
   ],
   "source": [
    "data_path = '../../dataset/bird_datasets/train'\n",
    "classes_path = '../../dataset/bird_datasets/classes.txt'\n",
    "training_labels_path = '../../dataset/bird_datasets/training_labels.txt'\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "WORKERS = 32\n",
    "\n",
    "print('torch version:' + torch.__version__)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('Available GPUs: ', end='')\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(torch.cuda.get_device_name(i), end=' ')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('CUDA is not available.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governmental-convergence",
   "metadata": {},
   "source": [
    "## read classes, labels txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "apart-patio",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_idx = {}\n",
    "with open(classes_path) as f:\n",
    "    for line in f.readlines():\n",
    "        label_num =  line.split(\".\")[0] \n",
    "        label_str =  line.split(\".\")[1][:-1]\n",
    "        class_to_idx[int(label_num) - 1] = label_str\n",
    "# print(class_to_idx)\n",
    "\n",
    "data_list = []\n",
    "with open(training_labels_path) as f:\n",
    "    for line in f.readlines():\n",
    "        file_name =  line.split(\" \")[0]\n",
    "        label_num =  int(line.split(\" \")[1].split(\".\")[0]) -1\n",
    "        label_str =  line.split(\" \")[1].split(\".\")[1][:-1]\n",
    "        data_list.append([file_name, label_num, label_str])\n",
    "\n",
    "train_data_list = data_list[:int(len(data_list) * 0.8)]\n",
    "val_data_list = data_list[int(len(data_list) * 0.8):int(len(data_list) * 0.9)]\n",
    "test_data_list = data_list[int(len(data_list) * 0.9):]\n",
    "\n",
    "# print(\"all data : \", len(data_list))\n",
    "# print(\"train data : \", len(train_data_list))\n",
    "# print(\"val data : \", len(val_data_list))\n",
    "# print(\"test data : \", len(test_data_list))\n",
    "# print(train_data_list[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-concern",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "convertible-powder",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "def get_trnsform():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224, scale=(1., 1.)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "    return transform\n",
    "trans = get_trnsform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historical-crest",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "#### Define dataset, and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "skilled-replication",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_EXTENSIONS = [\n",
    "    '.jpg', '.JPG', '.jpeg', '.JPEG',\n",
    "    '.png', '.PNG', '.ppm', '.PPM', '.bmp', '.BMP',\n",
    "]\n",
    "\n",
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in IMG_EXTENSIONS)\n",
    "\n",
    "def make_dataset(dir, data_list):\n",
    "    images = []\n",
    "    for img_name, idx, labels in data_list:\n",
    "        item = (img_name, int(idx))\n",
    "        images.append(item)\n",
    "    return images\n",
    "\n",
    "class BirdImageLoader(Dataset):\n",
    "    def __init__(self, root, data_list, class_to_idx, transform=None, target_transform=None):\n",
    "        imgs = make_dataset(root, data_list)\n",
    "\n",
    "        self.root = root\n",
    "        self.imgs = imgs\n",
    "        self.class_to_idx = class_to_idx\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path, target = self.imgs[index]\n",
    "        img = Image.open(os.path.join(self.root, path)).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "corrected-beauty",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/me/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 20, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test = BirdImageLoader(data_path, test_data_list, class_to_idx, transform=trans)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset_test,\n",
    "    num_workers=WORKERS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "dataset_test.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-enlargement",
   "metadata": {},
   "source": [
    "### test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "interracial-lafayette",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossEntropyLoss_fn = torch.nn.CrossEntropyLoss()\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n",
    "def pass_epoch(model, loader, mode = 'Train'):\n",
    "    loss = 0\n",
    "    loss_acc_top1 = 0\n",
    "    loss_acc_top5 = 0\n",
    "    \n",
    "    for i_batch, image_batch in tqdm(enumerate(loader)):\n",
    "        x, y = image_batch[0].to(device), image_batch[1].to(device)\n",
    "        if mode == 'Train':\n",
    "            model.train()\n",
    "        elif mode == 'Eval':\n",
    "            model.eval()\n",
    "        else:\n",
    "            print('error model mode!')\n",
    "        y_pred = model(x)\n",
    "\n",
    "        loss_batch = crossEntropyLoss_fn(y_pred, y)\n",
    "        loss_batch_acc_top = accuracy(y_pred, y, topk=(1, 5))\n",
    "\n",
    "        if mode == 'Train':\n",
    "            model_optimizer.zero_grad()\n",
    "            loss_batch.backward()\n",
    "            model_optimizer.step()\n",
    "        \n",
    "        loss += loss_batch.detach().cpu()\n",
    "        loss_acc_top1 += loss_batch_acc_top[0]\n",
    "        loss_acc_top5 += loss_batch_acc_top[1]\n",
    "        \n",
    "    loss /= (i_batch + 1)\n",
    "    loss_acc_top1 /= (i_batch + 1)\n",
    "    loss_acc_top5 /= (i_batch + 1)\n",
    "    \n",
    "    return loss, loss_acc_top1, loss_acc_top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "therapeutic-bonus",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(path, idx = 99):\n",
    "    with torch.no_grad():\n",
    "        model = torch.load('{}/checkpoint.pth.tar'.format(path))\n",
    "#         model = models.resnet50(pretrained=True).to(device)\n",
    "        model.load_state_dict(torch.load('{}/checkpoint_{}.pth.tar'.format(path, idx))['state_dict'])\n",
    "        val_loss, val_acc_top1, val_acc_top5 = pass_epoch(model,test_loader, 'Eval') \n",
    "    print(\"val_loss \", val_loss.to('cpu').numpy(), \"val_acc_top1\", val_acc_top1.to('cpu').numpy(), \"val_acc_top5 \", val_acc_top5.to('cpu').numpy())\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "treated-scout",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:01,  7.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8443) tensor([46.8750], device='cuda:0') tensor([78.0208], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_model('model/model_bird_res50_LR5', '0015')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "narrative-electric",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:01,  7.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.5304) tensor([43.3333], device='cuda:0') tensor([71.4583], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_model('model/model_bird_resnet50', '0015')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "blocked-offering",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7048) tensor([49.7917], device='cuda:0') tensor([73.5417], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_model('model/model_bird_res50_SGD', '0050')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "judicial-minutes",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:01,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6031) tensor([45.5208], device='cuda:0') tensor([77.8125], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_model('model/model_bird_res50_SGD', '0060')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "split-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1976) tensor([48.6458], device='cuda:0') tensor([77.3958], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_model('model/model_bird_resnet50_all_aug', '0005')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "interpreted-military",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:01,  7.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3349) tensor([46.2500], device='cuda:0') tensor([76.9792], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_model('model/model_bird_resnet50_all_aug', '0019')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "beginning-arbor",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8569) tensor([55.6250], device='cuda:0') tensor([74.7917], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_model('model/model_bird_resnet50_all_aug', '0095')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "auburn-directive",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:01,  8.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7659) tensor([55.9375], device='cuda:0') tensor([83.8542], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_model('model/model_bird_resnet50_all_aug_RL', '0022')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "asian-riverside",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:01,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7799) tensor([55.9375], device='cuda:0') tensor([82.7083], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_model('model/model_bird_resnet50_all_aug_RL', '0027')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "unable-brighton",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:01,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7091) tensor([66.3542], device='cuda:0') tensor([92.2917], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_model('model/model_bird_vit', '0028')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "polished-liberia",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:03,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0902) tensor([76.8750], device='cuda:0') tensor([96.5625], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_model('model/model_bird_vit_MultiStepLR', '0050')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ahead-sweden",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:03,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss  0.8201518 val_acc_top1 [78.75] val_acc_top5  [96.25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_model('model/model_bird_vit_ReduceLROnPlateau', '0046')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "black-audience",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:01,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss  0.63634455 val_acc_top1 [80.625] val_acc_top5  [96.875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_model('model/model_bird_vit_SGD', '0047')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "funny-capability",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:01,  5.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss  0.7801565 val_acc_top1 [81.875] val_acc_top5  [97.8125]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_model('model/model_bird_vit_CrossEntropyLS', '0047')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "expired-translation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:01,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss  0.18112554 val_acc_top1 [98.75] val_acc_top5  [100.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_model('model/model_bird_vit_AllData', '0047')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "welcome-million",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:03,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss  0.80037576 val_acc_top1 [81.5625] val_acc_top5  [97.8125]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_model('model/model_bird_vit_CrossEntropyLS', '0074')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "regular-daily",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:03,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss  0.7540843 val_acc_top1 [82.5] val_acc_top5  [97.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_model('model/model_bird_vit_vic', '0031')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "moving-estimate",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:03,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss  0.7697259 val_acc_top1 [81.25] val_acc_top5  [97.1875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_model('model/model_bird_vit_vic', '0035')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
