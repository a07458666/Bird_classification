{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "identified-matter",
   "metadata": {},
   "source": [
    "# answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interracial-kuwait",
   "metadata": {},
   "source": [
    "### import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "seven-attribute",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "from os import listdir\n",
    "from os import walk\n",
    "from torch import nn\n",
    "from tqdm import tqdm \n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torchvision import datasets, transforms\n",
    "from facenet_pytorch import InceptionResnetV1, fixed_image_standardization\n",
    "\n",
    "import PIL.Image as Image\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unique-simple",
   "metadata": {},
   "source": [
    "### check gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ideal-offense",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version:1.8.0\n",
      "Available GPUs: GeForce RTX 2080 Ti GeForce GTX 1080 Ti "
     ]
    }
   ],
   "source": [
    "data_path = '../../dataset/bird_datasets/test'\n",
    "classes_path = '../../dataset/bird_datasets/classes.txt'\n",
    "test_filename_path = '../../dataset/bird_datasets/testing_img_order.txt'\n",
    "\n",
    "print('torch version:' + torch.__version__)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('Available GPUs: ', end='')\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(torch.cuda.get_device_name(i), end=' ')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('CUDA is not available.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conditional-circular",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "controlled-prime",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "def get_trnsform():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((300, 300)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "    return transform\n",
    "trans = get_trnsform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cellular-mitchell",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_foloder = 'model/model_bird_resnet50'\n",
    "with torch.no_grad():\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    model.load_state_dict(torch.load('{}/checkpoint_0020.pth.tar'.format(model_foloder))['state_dict'])\n",
    "    model.eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "descending-facing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(path):\n",
    "    img = Image.open(os.path.join(data_path, path)).convert('RGB')\n",
    "    m = nn.Softmax(dim=1)\n",
    "    data = trans(img).unsqueeze(0).to(device)\n",
    "    y = model(data)\n",
    "    output = torch.argmax(m(y)) + 1\n",
    "    return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-gibson",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 2270/3033 [00:59<00:21, 35.66it/s]"
     ]
    }
   ],
   "source": [
    "with open(test_filename_path) as f:\n",
    "     test_images = [x.strip() for x in f.readlines()]  # all the testing images\n",
    "\n",
    "submission = []\n",
    "for img in tqdm(test_images):  # image order is important to your result\n",
    "    predicted_class = predict(img)\n",
    "    submission.append([img, predicted_class])\n",
    "\n",
    "np.savetxt('answer.txt', submission, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-dominican",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
