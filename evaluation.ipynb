{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "framed-neighbor",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-discipline",
   "metadata": {},
   "source": [
    "### import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "portable-photograph",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "from os import listdir\n",
    "from os import walk\n",
    "from torch import nn\n",
    "from tqdm import tqdm \n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torchvision import datasets, transforms\n",
    "from facenet_pytorch import InceptionResnetV1, fixed_image_standardization\n",
    "\n",
    "import PIL.Image as Image\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "through-factory",
   "metadata": {},
   "source": [
    "### check gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "reasonable-earth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version:1.8.0\n",
      "Available GPUs: GeForce RTX 2080 Ti GeForce GTX 1080 Ti "
     ]
    }
   ],
   "source": [
    "data_path = '../../dataset/bird_datasets/train'\n",
    "classes_path = '../../dataset/bird_datasets/classes.txt'\n",
    "training_labels_path = '../../dataset/bird_datasets/training_labels.txt'\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "WORKERS = 32\n",
    "\n",
    "print('torch version:' + torch.__version__)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('Available GPUs: ', end='')\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(torch.cuda.get_device_name(i), end=' ')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('CUDA is not available.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "military-jones",
   "metadata": {},
   "source": [
    "## read classes, labels txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bridal-parent",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_idx = {}\n",
    "with open(classes_path) as f:\n",
    "    for line in f.readlines():\n",
    "        label_num =  line.split(\".\")[0] \n",
    "        label_str =  line.split(\".\")[1][:-1]\n",
    "        class_to_idx[int(label_num) - 1] = label_str\n",
    "# print(class_to_idx)\n",
    "\n",
    "data_list = []\n",
    "with open(training_labels_path) as f:\n",
    "    for line in f.readlines():\n",
    "        file_name =  line.split(\" \")[0]\n",
    "        label_num =  int(line.split(\" \")[1].split(\".\")[0]) -1\n",
    "        label_str =  line.split(\" \")[1].split(\".\")[1][:-1]\n",
    "        data_list.append([file_name, label_num, label_str])\n",
    "\n",
    "train_data_list = data_list[:int(len(data_list) * 0.8)]\n",
    "val_data_list = data_list[int(len(data_list) * 0.8):int(len(data_list) * 0.9)]\n",
    "test_data_list = data_list[int(len(data_list) * 0.9):]\n",
    "\n",
    "# print(\"all data : \", len(data_list))\n",
    "# print(\"train data : \", len(train_data_list))\n",
    "# print(\"val data : \", len(val_data_list))\n",
    "# print(\"test data : \", len(test_data_list))\n",
    "# print(train_data_list[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-vertical",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "political-leeds",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "def get_trnsform():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224, scale=(1., 1.)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "    return transform\n",
    "trans = get_trnsform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-clarity",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "#### Define dataset, and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "confidential-inventory",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_EXTENSIONS = [\n",
    "    '.jpg', '.JPG', '.jpeg', '.JPEG',\n",
    "    '.png', '.PNG', '.ppm', '.PPM', '.bmp', '.BMP',\n",
    "]\n",
    "\n",
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in IMG_EXTENSIONS)\n",
    "\n",
    "def make_dataset(dir, data_list):\n",
    "    images = []\n",
    "    for img_name, idx, labels in data_list:\n",
    "        item = (img_name, int(idx))\n",
    "        images.append(item)\n",
    "    return images\n",
    "\n",
    "class BirdImageLoader(Dataset):\n",
    "    def __init__(self, root, data_list, class_to_idx, transform=None, target_transform=None):\n",
    "        imgs = make_dataset(root, data_list)\n",
    "\n",
    "        self.root = root\n",
    "        self.imgs = imgs\n",
    "        self.class_to_idx = class_to_idx\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path, target = self.imgs[index]\n",
    "        img = Image.open(os.path.join(self.root, path)).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "independent-robinson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test = BirdImageLoader(data_path, test_data_list, class_to_idx, transform=trans)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset_test,\n",
    "    num_workers=WORKERS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "dataset_test.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-confidence",
   "metadata": {},
   "source": [
    "### test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "monetary-thomson",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossEntropyLoss_fn = torch.nn.CrossEntropyLoss()\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n",
    "def pass_epoch(model, loader, mode = 'Train'):\n",
    "    loss = 0\n",
    "    loss_acc_top1 = 0\n",
    "    loss_acc_top5 = 0\n",
    "    \n",
    "    for i_batch, image_batch in tqdm(enumerate(loader)):\n",
    "        x, y = image_batch[0].to(device), image_batch[1].to(device)\n",
    "        if mode == 'Train':\n",
    "            model.train()\n",
    "        elif mode == 'Eval':\n",
    "            model.eval()\n",
    "        else:\n",
    "            print('error model mode!')\n",
    "        y_pred = model(x)\n",
    "\n",
    "        loss_batch = crossEntropyLoss_fn(y_pred, y)\n",
    "        loss_batch_acc_top = accuracy(y_pred, y, topk=(1, 5))\n",
    "\n",
    "        if mode == 'Train':\n",
    "            model_optimizer.zero_grad()\n",
    "            loss_batch.backward()\n",
    "            model_optimizer.step()\n",
    "        \n",
    "        loss += loss_batch.detach().cpu()\n",
    "        loss_acc_top1 += loss_batch_acc_top[0]\n",
    "        loss_acc_top5 += loss_batch_acc_top[1]\n",
    "        \n",
    "    loss /= (i_batch + 1)\n",
    "    loss_acc_top1 /= (i_batch + 1)\n",
    "    loss_acc_top5 /= (i_batch + 1)\n",
    "    \n",
    "    return loss, loss_acc_top1, loss_acc_top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "sexual-commodity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(path, idx = 99):\n",
    "    with torch.no_grad():\n",
    "        #model = torch.load('{}/checkpoint.pth.tar'.format(output_foloder))\n",
    "        model = models.resnet50(pretrained=True).to(device)\n",
    "        model.load_state_dict(torch.load('{}/checkpoint_{}.pth.tar'.format(path, idx))['state_dict'])\n",
    "        val_loss, val_acc_top1, val_acc_top5 = pass_epoch(model,test_loader, 'Eval') \n",
    "    print(val_loss, val_acc_top1, val_acc_top5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "excellent-shelf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:01,  7.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8450) tensor([46.5625], device='cuda:0') tensor([78.0208], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "output_foloder = 'model/model_bird_res50_LR5'\n",
    "with torch.no_grad():\n",
    "    #model = torch.load('{}/checkpoint.pth.tar'.format(output_foloder))\n",
    "    model = models.resnet50(pretrained=True).to(device)\n",
    "    model.load_state_dict(torch.load('{}/checkpoint_0015.pth.tar'.format(output_foloder))['state_dict'])\n",
    "    val_loss, val_acc_top1, val_acc_top5 = pass_epoch(test_loader, 'Eval') \n",
    "print(val_loss, val_acc_top1, val_acc_top5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "coupled-collaboration",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:01,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.4081) tensor([44.5833], device='cuda:0') tensor([69.0625], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "output_foloder = 'model/model_bird_resnet50'\n",
    "with torch.no_grad():\n",
    "    #model = torch.load('{}/checkpoint.pth.tar'.format(output_foloder))\n",
    "    model = models.resnet50(pretrained=True).to(device)\n",
    "    model.load_state_dict(torch.load('{}/checkpoint_0020.pth.tar'.format(output_foloder))['state_dict'])\n",
    "    val_loss, val_acc_top1, val_acc_top5 = pass_epoch(test_loader, 'Eval') \n",
    "print(val_loss, val_acc_top1, val_acc_top5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "original-tuition",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:01,  6.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8448) tensor([46.8750], device='cuda:0') tensor([78.0208], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_model('model/model_bird_res50_LR5', '0015')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "structural-champion",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:01,  7.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.5304) tensor([43.3333], device='cuda:0') tensor([71.4583], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_model('model/model_bird_resnet50', '0015')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "serial-jacksonville",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7048) tensor([49.7917], device='cuda:0') tensor([73.5417], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_model('model/model_bird_res50_SGD', '0050')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "authorized-consistency",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:01,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6031) tensor([45.5208], device='cuda:0') tensor([77.8125], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_model('model/model_bird_res50_SGD', '0060')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "comfortable-mouse",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1976) tensor([48.6458], device='cuda:0') tensor([77.3958], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_model('model/model_bird_resnet50_all_aug', '0005')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "marked-bathroom",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:01,  7.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3349) tensor([46.2500], device='cuda:0') tensor([76.9792], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_model('model/model_bird_resnet50_all_aug', '0019')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-title",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
