{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "configured-rental",
   "metadata": {},
   "source": [
    "# swin_transformer\n",
    "<img src=\"img/swin_transformer.png\" width=\"100%\">  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "viral-glossary",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../dataset/bird_datasets/train'\n",
    "classes_path = '../../dataset/bird_datasets/classes.txt'\n",
    "training_labels_path = '../../dataset/bird_datasets/training_labels.txt'\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "WORKERS = 16\n",
    "epochs = 100\n",
    "learning_rate = 2e-4\n",
    "weight_decay = 1e-4\n",
    "momentum = 0.9\n",
    "label_smooth=0.2\n",
    "# pretrain = None\n",
    "pretrain = 'model/model_bird_vic_simsiam_pretrain/checkpoint.pth.tar'\n",
    "\n",
    "output_foloder = 'model/model_bird_vit_vic_TripletLoss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "phantom-valentine",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('runs/' + output_foloder, comment=f' batch_size={BATCH_SIZE} lr={learning_rate}')\n",
    "writer.add_text('Remark', 'batch_size = {}'.format(BATCH_SIZE) , 0)\n",
    "writer.add_text('Remark', 'learning_rate = {}'.format(learning_rate) , 0)\n",
    "writer.add_text('Remark', 'momentum = {}'.format(momentum) , 0)\n",
    "writer.add_text('Remark', 'weight_decay = {}'.format(weight_decay) , 0)\n",
    "writer.add_text('Remark', 'output_foloder = {}'.format(output_foloder), 0)\n",
    "writer.add_text('Remark', 'pretrain = {}'.format(pretrain), 0)\n",
    "writer.add_text('Remark', 'label_smooth = {}'.format(label_smooth), 0)\n",
    "writer.add_text('Remark', 'TripletLoss', 0)\n",
    "\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "later-ministry",
   "metadata": {},
   "source": [
    "# GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "concerned-allocation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "from os import listdir\n",
    "from os import walk\n",
    "from torch import nn\n",
    "from tqdm import tqdm \n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import MultiStepLR, StepLR, ReduceLROnPlateau\n",
    "from torchvision import datasets, transforms\n",
    "# from swin_transformer_pytorch import SwinTransformer\n",
    "import torchvision.models as models\n",
    "from loss_functions.CrossEntropyLS import CrossEntropyLS\n",
    "from loss_functions.triplet_loss import TripletLoss\n",
    "\n",
    "import PIL.Image as Image\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "from torch.cuda.amp import GradScaler, autocast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "strong-argument",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version:1.9.0+cu102\n",
      "Available GPUs: GeForce RTX 2080 Ti GeForce GTX 1080 Ti "
     ]
    }
   ],
   "source": [
    "print('torch version:' + torch.__version__)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('Available GPUs: ', end='')\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(torch.cuda.get_device_name(i), end=' ')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('CUDA is not available.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flexible-funeral",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automotive-slovenia",
   "metadata": {},
   "source": [
    "#### Define dataset, and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "smaller-train",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_EXTENSIONS = [\n",
    "    '.jpg', '.JPG', '.jpeg', '.JPEG',\n",
    "    '.png', '.PNG', '.ppm', '.PPM', '.bmp', '.BMP',\n",
    "]\n",
    "\n",
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in IMG_EXTENSIONS)\n",
    "\n",
    "def make_dataset(dir, data_list):\n",
    "    images = []\n",
    "    for img_name, idx, labels in data_list:\n",
    "        item = (img_name, int(idx))\n",
    "        images.append(item)\n",
    "    return images\n",
    "\n",
    "class BirdImageLoader(Dataset):\n",
    "    def __init__(self, root, data_list, class_to_idx, transform=None, target_transform=None):\n",
    "        imgs = make_dataset(root, data_list)\n",
    "\n",
    "        self.root = root\n",
    "        self.imgs = imgs\n",
    "        self.class_to_idx = class_to_idx\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path, target = self.imgs[index]\n",
    "        img = Image.open(os.path.join(self.root, path)).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "future-device",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cultural-watson",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFilter\n",
    "import random\n",
    "\n",
    "class GaussianBlur(object):\n",
    "    def __init__(self, sigma=[.1, 2.]):\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def __call__(self, x):\n",
    "        sigma = random.uniform(self.sigma[0], self.sigma[1])\n",
    "        x = x.filter(ImageFilter.GaussianBlur(radius=sigma))\n",
    "        return x\n",
    "    \n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# https://github.com/aniket03/self_supervised_bird_classification/blob/master/dataset_helpers.py\n",
    "def all_in_aug():\n",
    "    all_in_transform = transforms.Compose([\n",
    "    transforms.Resize((300, 300)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=[0.5, 1.5]),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.CenterCrop((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    return all_in_transform\n",
    "\n",
    "def get_aug_trnsform():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224, scale=(0.2, 1.)),\n",
    "        transforms.RandomApply([\n",
    "            transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)  # not strengthened\n",
    "        ], p=0.8),\n",
    "        transforms.RandomGrayscale(p=0.2),\n",
    "        transforms.RandomApply([GaussianBlur([.1, 2.])], p=0.5),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "    return transform\n",
    "\n",
    "def get_trnsform():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224, scale=(1., 1.)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "    return transform\n",
    "trans_aug = get_aug_trnsform()\n",
    "trans = get_trnsform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-burning",
   "metadata": {},
   "source": [
    "## read classes txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "south-floating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Black_footed_Albatross', 1: 'Laysan_Albatross', 2: 'Sooty_Albatross', 3: 'Groove_billed_Ani', 4: 'Crested_Auklet', 5: 'Least_Auklet', 6: 'Parakeet_Auklet', 7: 'Rhinoceros_Auklet', 8: 'Brewer_Blackbird', 9: 'Red_winged_Blackbird', 10: 'Rusty_Blackbird', 11: 'Yellow_headed_Blackbird', 12: 'Bobolink', 13: 'Indigo_Bunting', 14: 'Lazuli_Bunting', 15: 'Painted_Bunting', 16: 'Cardinal', 17: 'Spotted_Catbird', 18: 'Gray_Catbird', 19: 'Yellow_breasted_Chat', 20: 'Eastern_Towhee', 21: 'Chuck_will_Widow', 22: 'Brandt_Cormorant', 23: 'Red_faced_Cormorant', 24: 'Pelagic_Cormorant', 25: 'Bronzed_Cowbird', 26: 'Shiny_Cowbird', 27: 'Brown_Creeper', 28: 'American_Crow', 29: 'Fish_Crow', 30: 'Black_billed_Cuckoo', 31: 'Mangrove_Cuckoo', 32: 'Yellow_billed_Cuckoo', 33: 'Gray_crowned_Rosy_Finch', 34: 'Purple_Finch', 35: 'Northern_Flicker', 36: 'Acadian_Flycatcher', 37: 'Great_Crested_Flycatcher', 38: 'Least_Flycatcher', 39: 'Olive_sided_Flycatcher', 40: 'Scissor_tailed_Flycatcher', 41: 'Vermilion_Flycatcher', 42: 'Yellow_bellied_Flycatcher', 43: 'Frigatebird', 44: 'Northern_Fulmar', 45: 'Gadwall', 46: 'American_Goldfinch', 47: 'European_Goldfinch', 48: 'Boat_tailed_Grackle', 49: 'Eared_Grebe', 50: 'Horned_Grebe', 51: 'Pied_billed_Grebe', 52: 'Western_Grebe', 53: 'Blue_Grosbeak', 54: 'Evening_Grosbeak', 55: 'Pine_Grosbeak', 56: 'Rose_breasted_Grosbeak', 57: 'Pigeon_Guillemot', 58: 'California_Gull', 59: 'Glaucous_winged_Gull', 60: 'Heermann_Gull', 61: 'Herring_Gull', 62: 'Ivory_Gull', 63: 'Ring_billed_Gull', 64: 'Slaty_backed_Gull', 65: 'Western_Gull', 66: 'Anna_Hummingbird', 67: 'Ruby_throated_Hummingbird', 68: 'Rufous_Hummingbird', 69: 'Green_Violetear', 70: 'Long_tailed_Jaeger', 71: 'Pomarine_Jaeger', 72: 'Blue_Jay', 73: 'Florida_Jay', 74: 'Green_Jay', 75: 'Dark_eyed_Junco', 76: 'Tropical_Kingbird', 77: 'Gray_Kingbird', 78: 'Belted_Kingfisher', 79: 'Green_Kingfisher', 80: 'Pied_Kingfisher', 81: 'Ringed_Kingfisher', 82: 'White_breasted_Kingfisher', 83: 'Red_legged_Kittiwake', 84: 'Horned_Lark', 85: 'Pacific_Loon', 86: 'Mallard', 87: 'Western_Meadowlark', 88: 'Hooded_Merganser', 89: 'Red_breasted_Merganser', 90: 'Mockingbird', 91: 'Nighthawk', 92: 'Clark_Nutcracker', 93: 'White_breasted_Nuthatch', 94: 'Baltimore_Oriole', 95: 'Hooded_Oriole', 96: 'Orchard_Oriole', 97: 'Scott_Oriole', 98: 'Ovenbird', 99: 'Brown_Pelican', 100: 'White_Pelican', 101: 'Western_Wood_Pewee', 102: 'Sayornis', 103: 'American_Pipit', 104: 'Whip_poor_Will', 105: 'Horned_Puffin', 106: 'Common_Raven', 107: 'White_necked_Raven', 108: 'American_Redstart', 109: 'Geococcyx', 110: 'Loggerhead_Shrike', 111: 'Great_Grey_Shrike', 112: 'Baird_Sparrow', 113: 'Black_throated_Sparrow', 114: 'Brewer_Sparrow', 115: 'Chipping_Sparrow', 116: 'Clay_colored_Sparrow', 117: 'House_Sparrow', 118: 'Field_Sparrow', 119: 'Fox_Sparrow', 120: 'Grasshopper_Sparrow', 121: 'Harris_Sparrow', 122: 'Henslow_Sparrow', 123: 'Le_Conte_Sparrow', 124: 'Lincoln_Sparrow', 125: 'Nelson_Sharp_tailed_Sparrow', 126: 'Savannah_Sparrow', 127: 'Seaside_Sparrow', 128: 'Song_Sparrow', 129: 'Tree_Sparrow', 130: 'Vesper_Sparrow', 131: 'White_crowned_Sparrow', 132: 'White_throated_Sparrow', 133: 'Cape_Glossy_Starling', 134: 'Bank_Swallow', 135: 'Barn_Swallow', 136: 'Cliff_Swallow', 137: 'Tree_Swallow', 138: 'Scarlet_Tanager', 139: 'Summer_Tanager', 140: 'Artic_Tern', 141: 'Black_Tern', 142: 'Caspian_Tern', 143: 'Common_Tern', 144: 'Elegant_Tern', 145: 'Forsters_Tern', 146: 'Least_Tern', 147: 'Green_tailed_Towhee', 148: 'Brown_Thrasher', 149: 'Sage_Thrasher', 150: 'Black_capped_Vireo', 151: 'Blue_headed_Vireo', 152: 'Philadelphia_Vireo', 153: 'Red_eyed_Vireo', 154: 'Warbling_Vireo', 155: 'White_eyed_Vireo', 156: 'Yellow_throated_Vireo', 157: 'Bay_breasted_Warbler', 158: 'Black_and_white_Warbler', 159: 'Black_throated_Blue_Warbler', 160: 'Blue_winged_Warbler', 161: 'Canada_Warbler', 162: 'Cape_May_Warbler', 163: 'Cerulean_Warbler', 164: 'Chestnut_sided_Warbler', 165: 'Golden_winged_Warbler', 166: 'Hooded_Warbler', 167: 'Kentucky_Warbler', 168: 'Magnolia_Warbler', 169: 'Mourning_Warbler', 170: 'Myrtle_Warbler', 171: 'Nashville_Warbler', 172: 'Orange_crowned_Warbler', 173: 'Palm_Warbler', 174: 'Pine_Warbler', 175: 'Prairie_Warbler', 176: 'Prothonotary_Warbler', 177: 'Swainson_Warbler', 178: 'Tennessee_Warbler', 179: 'Wilson_Warbler', 180: 'Worm_eating_Warbler', 181: 'Yellow_Warbler', 182: 'Northern_Waterthrush', 183: 'Louisiana_Waterthrush', 184: 'Bohemian_Waxwing', 185: 'Cedar_Waxwing', 186: 'American_Three_toed_Woodpecker', 187: 'Pileated_Woodpecker', 188: 'Red_bellied_Woodpecker', 189: 'Red_cockaded_Woodpecker', 190: 'Red_headed_Woodpecker', 191: 'Downy_Woodpecker', 192: 'Bewick_Wren', 193: 'Cactus_Wren', 194: 'Carolina_Wren', 195: 'House_Wren', 196: 'Marsh_Wren', 197: 'Rock_Wren', 198: 'Winter_Wren', 199: 'Common_Yellowthroat'}\n"
     ]
    }
   ],
   "source": [
    "class_to_idx = {}\n",
    "with open(classes_path) as f:\n",
    "    for line in f.readlines():\n",
    "        label_num =  line.split(\".\")[0] \n",
    "        label_str =  line.split(\".\")[1][:-1]\n",
    "        class_to_idx[int(label_num) - 1] = label_str\n",
    "print(class_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-advice",
   "metadata": {},
   "source": [
    "## read labels txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "stopped-carolina",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all data :  3000\n",
      "train data :  2400\n",
      "val data :  300\n",
      "test data :  300\n",
      "[['4283.jpg', 114, 'Brewer_Sparrow'], ['3982.jpg', 161, 'Canada_Warbler'], ['5836.jpg', 143, 'Common_Tern'], ['5980.jpg', 7, 'Rhinoceros_Auklet'], ['4168.jpg', 160, 'Blue_winged_Warbler'], ['2352.jpg', 60, 'Heermann_Gull'], ['0511.jpg', 37, 'Great_Crested_Flycatcher'], ['4492.jpg', 146, 'Least_Tern'], ['1254.jpg', 131, 'White_crowned_Sparrow'], ['2792.jpg', 176, 'Prothonotary_Warbler']]\n"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "with open(training_labels_path) as f:\n",
    "    for line in f.readlines():\n",
    "        file_name =  line.split(\" \")[0]\n",
    "        label_num =  int(line.split(\" \")[1].split(\".\")[0]) -1\n",
    "        label_str =  line.split(\" \")[1].split(\".\")[1][:-1]\n",
    "        data_list.append([file_name, label_num, label_str])\n",
    "\n",
    "train_data_list = data_list[:int(len(data_list) * 0.8)]\n",
    "val_data_list = data_list[int(len(data_list) * 0.8):int(len(data_list) * 0.9)]\n",
    "test_data_list = data_list[int(len(data_list) * 0.9):]\n",
    "\n",
    "# train_data_list = data_list[:int(len(data_list))]\n",
    "# val_data_list = data_list[int(len(data_list) * 0.8):int(len(data_list) * 1)]\n",
    "# test_data_list = data_list[int(len(data_list) * 0.9):]\n",
    "\n",
    "\n",
    "print(\"all data : \", len(data_list))\n",
    "print(\"train data : \", len(train_data_list))\n",
    "print(\"val data : \", len(val_data_list))\n",
    "print(\"test data : \", len(test_data_list))\n",
    "print(train_data_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "protected-enhancement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_to_idx  200\n",
      "val_loader  200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2400"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train = BirdImageLoader(data_path, train_data_list, class_to_idx, transform=trans_aug)\n",
    "dataset_val = BirdImageLoader(data_path, val_data_list, class_to_idx, transform=trans)\n",
    "dataset_test = BirdImageLoader(data_path, test_data_list, class_to_idx, transform=trans)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset_train,\n",
    "    num_workers=WORKERS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset_val,\n",
    "    num_workers=WORKERS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset_test,\n",
    "    num_workers=WORKERS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print('class_to_idx ', len(dataset_train.class_to_idx))\n",
    "print('val_loader ', len(dataset_train.class_to_idx))\n",
    "dataset_train.__len__()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transsexual-certification",
   "metadata": {},
   "source": [
    "### Test Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "phantom-directive",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "0it [00:00, ?it/s]\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3437, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-10-1c353b4ce518>\", line 17, in <module>\n",
      "    plt.show()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/matplotlib/pyplot.py\", line 353, in show\n",
      "    return _backend_mod.show(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/ipykernel/pylab/backend_inline.py\", line 43, in show\n",
      "    metadata=_fetch_figure_metadata(figure_manager.canvas.figure)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/display.py\", line 313, in display\n",
      "    format_dict, md_dict = format(obj, include=include, exclude=exclude)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/formatters.py\", line 180, in format\n",
      "    data = formatter(obj)\n",
      "  File \"<decorator-gen-2>\", line 2, in __call__\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/formatters.py\", line 224, in catch_format_error\n",
      "    r = method(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/formatters.py\", line 341, in __call__\n",
      "    return printer(obj)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/pylabtools.py\", line 248, in <lambda>\n",
      "    png_formatter.for_type(Figure, lambda fig: print_figure(fig, 'png', **kwargs))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/pylabtools.py\", line 132, in print_figure\n",
      "    fig.canvas.print_figure(bytes_io, **kw)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/matplotlib/backend_bases.py\", line 2193, in print_figure\n",
      "    self.figure.draw(renderer)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/matplotlib/artist.py\", line 41, in draw_wrapper\n",
      "    return draw(artist, renderer, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/matplotlib/figure.py\", line 1864, in draw\n",
      "    renderer, self, artists, self.suppressComposite)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/matplotlib/image.py\", line 131, in _draw_list_compositing_images\n",
      "    a.draw(renderer)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/matplotlib/artist.py\", line 41, in draw_wrapper\n",
      "    return draw(artist, renderer, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py\", line 411, in wrapper\n",
      "    return func(*inner_args, **inner_kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/matplotlib/axes/_base.py\", line 2747, in draw\n",
      "    mimage._draw_list_compositing_images(renderer, self, artists)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/matplotlib/image.py\", line 131, in _draw_list_compositing_images\n",
      "    a.draw(renderer)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/matplotlib/artist.py\", line 41, in draw_wrapper\n",
      "    return draw(artist, renderer, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/matplotlib/image.py\", line 644, in draw\n",
      "    renderer, renderer.get_image_magnification())\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/matplotlib/image.py\", line 929, in make_image\n",
      "    magnification, unsampled=unsampled)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/matplotlib/image.py\", line 553, in _make_image\n",
      "    self, A[..., 3], out_shape, t, alpha=alpha)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/matplotlib/image.py\", line 197, in _resample\n",
      "    image_obj.get_filterrad())\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/opt/conda/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/opt/conda/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/opt/conda/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/opt/conda/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/opt/conda/lib/python3.7/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/opt/conda/lib/python3.7/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/opt/conda/lib/python3.7/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_debug = BirdImageLoader(data_path, train_data_list, class_to_idx, transform=trans_aug)\n",
    "debug_loader = DataLoader(\n",
    "    dataset_debug,\n",
    "    num_workers=WORKERS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "for i_batch, image_batch in tqdm(enumerate(debug_loader)):\n",
    "    x, y = image_batch[0], image_batch[1]\n",
    "    ROW, COL = 2, 4\n",
    "    f, ax = plt.subplots(ROW, COL, figsize=(16, 7))\n",
    "    for i in range(ROW):\n",
    "        for j in range(COL):\n",
    "            img = x[i*COL+j]\n",
    "            ax[i][j].imshow(img.permute(1, 2, 0))\n",
    "    plt.show()\n",
    "    break\n",
    "print(y)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equal-bailey",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hourly-hollywood",
   "metadata": {},
   "source": [
    " ### define optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-republican",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make embedding to length=1\n",
    "class L2_norm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(L2_norm, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.normalize(x, p=2, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-karaoke",
   "metadata": {},
   "source": [
    "### fix model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-partition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-bidding",
   "metadata": {},
   "source": [
    "## define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-provider",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = SwinTransformer(\n",
    "#     hidden_dim=96,\n",
    "#     layers=(2, 2, 6, 2),\n",
    "#     heads=(3, 6, 12, 24),\n",
    "#     channels=3,\n",
    "#     num_classes=len(dataset_train.class_to_idx),\n",
    "#     head_dim=32,\n",
    "#     window_size=7,\n",
    "#     downscaling_factors=(4, 2, 2, 2),\n",
    "#     relative_pos_embedding=True\n",
    "# )\n",
    "# dummy_x = torch.randn(1, 3, 224, 224)\n",
    "# logits = net(dummy_x)  # (1,3)\n",
    "# model = net.to(device)\n",
    "# print(net)\n",
    "# print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-procurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = timm.create_model('vit_base_patch16_224_miil_in21k', pretrained=True)\n",
    "\n",
    "if pretrain != None:\n",
    "    backbone = torch.load(pretrain).to(device)\n",
    "    set_parameter_requires_grad(backbone, False)\n",
    "\n",
    "projector = nn.Sequential(\n",
    "    nn.Linear(11221, 2048), nn.BatchNorm1d(2048), nn.ReLU(),\n",
    "    nn.Linear(2048, 512), nn.BatchNorm1d(512), nn.ReLU(),\n",
    "    nn.Linear(512, 200)\n",
    ")\n",
    "model = nn.Sequential(backbone, projector).to(device)\n",
    "model_optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum = momentum, weight_decay=weight_decay)\n",
    "\n",
    "model_scheduler = ReduceLROnPlateau(model_optimizer, 'min')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-archives",
   "metadata": {},
   "source": [
    "#### Define loss and evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-pride",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn = torch.nn.CrossEntropyLoss()\n",
    "loss_fn = CrossEntropyLS(label_smooth)\n",
    "loss_fn = TripletLoss(device)\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structural-reaction",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-sullivan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-engineer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_loss_hist(train_list, val_list, name='result'):\n",
    "    clear_output(wait=True)\n",
    "    plt.plot(train_list)\n",
    "    plt.plot(val_list)\n",
    "    plt.title(name)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'val'], loc='center right')\n",
    "    plt.savefig('{}/{}.png'.format(output_foloder, name))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pass_epoch(loader, mode = 'Train'):\n",
    "    loss = 0\n",
    "    acc_top1 = 0\n",
    "    acc_top5 = 0\n",
    "    \n",
    "    for i_batch, image_batch in tqdm(enumerate(loader)):\n",
    "        x, y = image_batch[0].to(device), image_batch[1].to(device)\n",
    "        if mode == 'Train':\n",
    "            model.train()\n",
    "        elif mode == 'Eval':\n",
    "            model.eval()\n",
    "        else:\n",
    "            print('error model mode!')\n",
    "        y_pred = model(x)\n",
    "\n",
    "        loss_batch = loss_fn(y_pred, y)\n",
    "        loss_batch_acc_top = accuracy(y_pred, y, topk=(1, 5))\n",
    "\n",
    "        if mode == 'Train':\n",
    "            model_optimizer.zero_grad()\n",
    "            scaler.scale(loss_batch).backward()\n",
    "            scaler.step(model_optimizer)\n",
    "            scaler.update()\n",
    "#             loss_batch.backward()\n",
    "            model_optimizer.step()\n",
    "        \n",
    "        loss += loss_batch.detach().cpu()\n",
    "        acc_top1 += loss_batch_acc_top[0]\n",
    "        acc_top5 += loss_batch_acc_top[1]\n",
    "        \n",
    "    loss /= (i_batch + 1)\n",
    "    acc_top1 /= (i_batch + 1)\n",
    "    acc_top5 /= (i_batch + 1)\n",
    "#     writer.add_scalar(str(\"loss/\" + mode), loss, epoch)\n",
    "#     writer.add_scalar(str(\"top1/\" + mode), acc_top1, epoch)\n",
    "#     writer.add_scalar(str(\"top5/\" + mode), acc_top5, epoch)\n",
    "    \n",
    "    return loss, acc_top1, acc_top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-tablet",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "train_loss_history = []\n",
    "train_acc_top1_history = []\n",
    "train_acc_top5_history = []\n",
    "\n",
    "\n",
    "val_loss_history = []\n",
    "val_acc_top1_history = []\n",
    "val_acc_top5_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hired-swift",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, '{}/checkpoint.pth.tar'.format(output_foloder))\n",
    "scaler = GradScaler()\n",
    "stop = 0\n",
    "min_val_loss = 9999\n",
    "for epoch in range(epochs):\n",
    "    print('\\nEpoch {}/{}'.format(epoch + 1, epochs))\n",
    "    print('-' * 10)\n",
    "    train_loss, train_acc_top1, train_acc_top5 = pass_epoch(train_loader, 'Train')  \n",
    "    with torch.no_grad():\n",
    "        val_loss, val_acc_top1, val_acc_top5 = pass_epoch(val_loader, 'Eval') \n",
    "\n",
    "    writer.add_scalars('loss', {'train':train_loss, 'val':val_loss}, epoch)\n",
    "    writer.add_scalars('top1', {'train':train_acc_top1, 'val':val_acc_top1}, epoch)\n",
    "    writer.add_scalars('top5', {'train':train_acc_top5, 'val':val_acc_top5}, epoch)\n",
    "\n",
    "    \n",
    "    train_loss_history.append(train_loss)\n",
    "    train_acc_top1_history.append(train_acc_top1)\n",
    "    train_acc_top5_history.append(train_acc_top5)\n",
    "\n",
    "\n",
    "    val_loss_history.append(val_loss)\n",
    "    val_acc_top1_history.append(val_acc_top1)\n",
    "    val_acc_top5_history.append(val_acc_top5)\n",
    "    \n",
    "    update_loss_hist(train_loss_history, val_loss_history, 'Loss')\n",
    "    update_loss_hist(train_acc_top5_history, val_acc_top5_history, 'Top5')\n",
    "    update_loss_hist(train_acc_top1_history, val_acc_top1_history, 'Top1')\n",
    "    model_scheduler.step(val_loss)\n",
    "    if (val_loss <= min_val_loss):\n",
    "        val_loss = min_val_loss\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'learning_rate': learning_rate,\n",
    "            'loss': 'CrossEntropyLoss',\n",
    "            'state_dict': model.state_dict(),\n",
    "        }, is_best=False, filename='{}/checkpoint_{:04d}.pth.tar'.format(output_foloder, epoch + 1))\n",
    "    else:\n",
    "        stop += 1\n",
    "        if (stop > 5):\n",
    "            print('early stopping')\n",
    "            break\n",
    "torch.save(model, '{}/checkpoint.pth.tar'.format(output_foloder))\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-recommendation",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, '{}/checkpoint.pth.tar'.format(output_foloder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-scotland",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
